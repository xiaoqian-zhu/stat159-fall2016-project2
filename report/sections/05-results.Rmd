
# Results

```{r results= 'asis', echo = FALSE}
MSE_five = as.matrix(c("ols" = ols_mse, "ridge" = ridge_mse, "lasso" = lasso_mse, "pcr" = pc_mse, "plsr" = pls_mse))
colnames(MSE_five) = "MSE"
print(xtable(MSE_five, caption = 'MSE of Five Regression Methods', digits = 5), comment = FALSE)
```

From the MSE table above, we find that all the MSE are very close to each other and the maximum difference between the MSE of ols and that of lasso. The regression with the smallest MSE is ols regression, where MSE = `r ols_mse`. As ols has the smallest MSE, then we can conlcude that ols is the best fitted model for the credit data set in this case. Aditionally, the one with the largest MSE is lasso regression, where MSE is euqual to `r lasso_mse`. this means tha lasso regression provides the worst fitted model for the credit dataset.This is a very interesting finding that extended approaches get worse model than ols regression. This is may because we do not have a very large number of variables or low ratio of number of observations to number of variables. Moreover, it is also possible that preditors ae highly correlated, thus lasso does not yeild good results in presense of high collinearity, results in the worst fit model.

Furthermore, we also include a trendline plot in which the official coefficients are compared.

```{r results= 'asis', echo = FALSE}
par(mfrow = c(1,1))
plot(five_matrix_coef[,2], xaxt = "n",xlab=" ", ylab = "Value", main = "Trend Lines of Coefficients for Five Regression Models", col = "black")
lines(five_matrix_coef[,2], col="black", lwd=2)
points(five_matrix_coef[,3],col= "red")
lines(five_matrix_coef[,3],col = "red")
points(five_matrix_coef[,4], col = "green")
lines(five_matrix_coef[,4],col = "green")
points(five_matrix_coef[,5], col = "yellow")
lines(five_matrix_coef[,5],col = "yellow")
points(five_matrix_coef[,6], col = "blue")
lines(five_matrix_coef[,6],col = "blue")
axis(1, at=1:12, labels=Variables, las=2,cex.axis=0.6)
legend(10,0.9,c('OLS','Ridge','Lasso','PCR','PLSR'), lty = c(1,1,1,1,1), lwd = c(2.5,2.5,2.5,2.5,2.5), col = c("black","red","green","yellow","blue"),merge = T)
abline(h = 0, lty = 3)
```

This trendline plot also allows us to compare how each type of regression models fit a model to the credit data set. We can see from the graph that the lines of PLSR, PCR and OLS are very close to each other, and even overlap. Lasso has the biggest variance with OLS generally. Ridge generally has smaller coefficients with OLS. Moreover, for variables like `Income`, it is almost same in each model, however, for varibles like `Rating` and `Limit`, these estimates vary widely in different regression methods.



